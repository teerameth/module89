{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = [224, 224, 3]\n",
    "NUM_CLASSES = 6\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "labelNames = [\"Bishop\", \"King\", \"Knight\", \"Pawn\", \"Queen\", \"Rook\"]\n",
    "labels = ['b', 'k', 'n', 'p', 'q', 'r']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import math\n",
    "from transform import order_points, poly2view_angle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Converting the values into features\n",
    "def _int64_feature(value):  # _int64 is used for numeric values\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "def _bytes_feature(value):  # _bytes is used for string/char values\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "tile_feature_description = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "def _parse_image_function(example_proto):\n",
    "    data = tf.io.parse_single_example(example_proto, tile_feature_description) # Parse the input tf.train.Example proto using dictionary.\n",
    "    # label = data['label']\n",
    "    label = tf.one_hot(indices=data['label'], depth=NUM_CLASSES, on_value=1.0, off_value=0.0)\n",
    "    image = tf.io.decode_png(data['image'])  # Auto detect image shape when decoded\n",
    "    output = {}\n",
    "    # return [image], [label]\n",
    "    return image, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset_config = json.load(open(os.path.join('../../config/dataset_config.json')))\n",
    "output_path = dataset_config['capture_path']\n",
    "top_tfrecord_pattern = os.path.join(output_path, 'top.tfrecords-????-of-????')\n",
    "side_tfrecord_pattern = os.path.join(output_path, 'side.tfrecords-????-of-????')\n",
    "\n",
    "# strategy = tf.distribute.MirroredStrategy() # Not connected to a TPU runtime. Using CPU/GPU strategy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 22:10:01.707380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:10:01.726871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:10:01.727309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:10:01.728476: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-24 22:10:01.728948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:10:01.729426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:10:01.729807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:10:02.260466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:10:02.260880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:10:02.261252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:10:02.261602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7200 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "shards = tf.data.TFRecordDataset.list_files(side_tfrecord_pattern)\n",
    "shards = shards.shuffle(buffer_size=1000) # Make sure to fully shuffle the list of tfrecord files.\n",
    "# Preprocesses 10 files concurrently and interleaves records from each file into a single, unified dataset.\n",
    "dataset = shards.interleave(\n",
    "    tf.data.TFRecordDataset,\n",
    "    cycle_length=10,\n",
    "    block_length=1)\n",
    "dataset = dataset.map(_parse_image_function, num_parallel_calls=4)\n",
    "split_filter = [0, 0, 0, 0, 0, 0, 0, 1, 1, 2]   # Use to filter dataset as train:val:test = 70:20:10\n",
    "train_set = dataset.enumerate() \\\n",
    "                    .filter(lambda x,y: x % 10 <= 6) \\\n",
    "                    .map(lambda x,y: y)\n",
    "val_set = dataset.enumerate() \\\n",
    "                    .filter(lambda x,y: x % 10 == 7 or x % 10 == 8) \\\n",
    "                    .map(lambda x,y: y)\n",
    "test_set = dataset.enumerate() \\\n",
    "                    .filter(lambda x,y: x % 10 == 9) \\\n",
    "                    .map(lambda x,y: y)\n",
    "train_set = train_set.shuffle(2000)\n",
    "train_set = train_set.batch(BATCH_SIZE, drop_remainder=True)\n",
    "val_set = val_set.shuffle(2000)\n",
    "val_set = val_set.batch(BATCH_SIZE, drop_remainder=True)\n",
    "test_set = test_set.shuffle(2000)\n",
    "test_set = test_set.batch(BATCH_SIZE, drop_remainder=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16711680/16705208 [==============================] - 2s 0us/step\n",
      "16719872/16705208 [==============================] - 2s 0us/step\n",
      "Number of layers in the base model:  237\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "\n",
    "\n",
    "img_augmentation = Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomRotation(factor=0.15),\n",
    "        tf.keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        tf.keras.layers.RandomFlip(),\n",
    "        tf.keras.layers.RandomContrast(factor=0.1),\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")\n",
    "base_model = tf.keras.applications.EfficientNetB0(input_shape=IMAGE_SIZE,\n",
    "                                                  include_top=False,\n",
    "                                                  weights='imagenet')\n",
    "# base_model = tf.keras.applications.MobileNetV2(input_shape=IMAGE_SIZE,\n",
    "#                                                include_top=False,\n",
    "#                                                weights='imagenet')\n",
    "\n",
    "# Add a classification head\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(NUM_CLASSES)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=IMAGE_SIZE)\n",
    "x = img_augmentation(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "base_model.trainable = True # Unlock some layers\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))   # 154 for MobileNetV2, 237 for EfficientNetB0\n",
    "\n",
    "unlock_at = 215\n",
    "# unlock_at = 135\n",
    "learning_rate = base_learning_rate\n",
    "\n",
    "for layer in base_model.layers[:unlock_at]: layer.trainable = False     # Freeze all the layers before the `unlock_at` layer\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "          loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "          metrics=['accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " random_rotation (RandomRota  (None, 224, 224, 3)      0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " random_translation (RandomT  (None, 224, 224, 3)      0         \n",
      " ranslation)                                                     \n",
      "                                                                 \n",
      " random_flip (RandomFlip)    (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " random_contrast (RandomCont  (None, 224, 224, 3)      0         \n",
      " rast)                                                           \n",
      "                                                                 \n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 7686      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,057,257\n",
      "Trainable params: 1,415,094\n",
      "Non-trainable params: 2,642,163\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "23"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 22:10:18.264210: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 1661 of 2000\n",
      "2022-04-24 22:10:19.889289: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2022-04-24 22:10:20.489476: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19267584 exceeds 10% of free system memory.\n",
      "2022-04-24 22:10:20.966153: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8204\n",
      "2022-04-24 22:10:21.367351: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 16s 16s/step - loss: 1.8570 - accuracy: 0.2266"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 22:10:23.301885: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19267584 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2/Unknown - 17s 970ms/step - loss: 1.9128 - accuracy: 0.1797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 22:10:24.307953: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19267584 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3/Unknown - 18s 987ms/step - loss: 1.9161 - accuracy: 0.1849"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 22:10:25.180930: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19267584 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4/Unknown - 19s 949ms/step - loss: 1.9171 - accuracy: 0.1797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 22:10:26.064883: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19267584 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 76s 676ms/step - loss: 1.9139 - accuracy: 0.1930\n",
      "initial loss: 1.91\n",
      "initial accuracy: 0.19\n"
     ]
    }
   ],
   "source": [
    "# First validation (before training: should be 16.67%)\n",
    "initial_epochs = 2\n",
    "loss0, accuracy0 = model.evaluate(test_set)\n",
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "    179/Unknown - 68s 352ms/step - loss: 0.7477 - accuracy: 0.7280"
     ]
    }
   ],
   "source": [
    "# Initial Training\n",
    "history = model.fit(train_set,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=val_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unlock_at = 175\n",
    "# unlock_at = 125\n",
    "learning_rate = base_learning_rate/10   # Lowering learning rate to 10% to prevent overfit\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fine_tune_epochs = 2\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_set,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         validation_data=val_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0.8, 1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_set)\n",
    "print('Test accuracy :', accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "checkpoint_path = \"/media/teera/SSD250GB/model/classification/chess/EfficientNetB0_piece/cp-{epoch:04d}.ckpt\"\n",
    "model.save_weights(checkpoint_path.format(epoch=20))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('/media/teera/SSD250GB/model/classification/chess/EfficientNetB0_piece/model.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "savedModel = tf.keras.models.load_model('/media/teera/SSD250GB/model/classification/chess/EfficientNetB0_piece/model.h5')\n",
    "savedModel.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}